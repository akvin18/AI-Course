{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Quiz: NumPy & Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. You are given a dataset with millions of rows. Why would using NumPy arrays or Pandas DataFrames be preferable to Python lists and dictionaries?\n",
    "\n",
    "2. You need to compute the mean income by city across a large dataset. Describe how you would approach this task using Pandas.\n",
    "\n",
    "3. Suppose you notice a large number of `NaN` values in your dataset. What steps would you take to decide whether to fill, drop, or investigate them?\n",
    "\n",
    "4. You suspect some columns in your dataset are highly correlated. How would you use NumPy or Pandas to confirm this?\n",
    "\n",
    "5. Describe a scenario where vectorized operations in NumPy would significantly improve performance compared to traditional Python loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Quiz: Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. You need to collect product data from an online store that doesn't offer an API. How would you approach this?\n",
    "\n",
    "2. What ethical and legal considerations should you account for when scraping websites?\n",
    "\n",
    "3. An API limits you to 1000 records per request. How would you plan to gather and store data from it efficiently?\n",
    "\n",
    "4. You are scraping data from a public news site. Sometimes pages fail to load. How would you make your scraping process more reliable?\n",
    "\n",
    "5. You’ve gathered data from multiple sources with overlapping content. What strategies would you use to reconcile and deduplicate it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Quiz: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. You find that 30% of values in a key column are missing. What steps would you take to decide how to handle them?\n",
    "\n",
    "2. Your data contains inconsistent category labels like 'NY', 'New York', 'new york'. How would you standardize them?\n",
    "\n",
    "3. A dataset has outliers that skew the mean. What strategies would you consider to treat or preserve those outliers?\n",
    "\n",
    "4. You need to ensure all numeric columns are correctly typed and free of non-numeric entries. How would you validate and enforce this?\n",
    "\n",
    "5. Describe how you would design a repeatable and auditable data cleaning pipeline for a continuously updated dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Quiz: Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. Your dataset is highly imbalanced (90% no, 10% yes). What data augmentation strategies could help and how would you validate them?\n",
    "\n",
    "2. You are working on a text classification task with limited data. What augmentation approaches might you try and why?\n",
    "\n",
    "3. Describe how feature engineering differs from data augmentation. Where might they overlap?\n",
    "\n",
    "4. How could synthetic data generation introduce bias into your model? What checks would you implement?\n",
    "\n",
    "5. Explain how data augmentation could be applied during model training in real time, rather than as a preprocessing step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment: End-to-End Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Build a small pipeline that simulates a real-world data task using NumPy, Pandas, and data preparation techniques.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. **Generate Data:**  \n",
    "   - Use NumPy to simulate a dataset of 1000 people with fields: `age`, `income`, `city`, and `purchase_status`.\n",
    "   - Add some missing values randomly.\n",
    "\n",
    "2. **Clean Data:**  \n",
    "   - Fill missing ages with the mean.\n",
    "   - Drop rows where `purchase_status` is missing.\n",
    "   - Convert `purchase_status` to binary: yes → 1, no → 0\n",
    "\n",
    "3. **Augment Data:**  \n",
    "   - Add a new feature: `age_group` based on age.\n",
    "   - Perform simple upsampling to balance `purchase_status`.\n",
    "\n",
    "4. **Output:**  \n",
    "   - Save the cleaned and augmented DataFrame as CSV.\n",
    "   - Print basic statistics (mean, value counts, etc.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
