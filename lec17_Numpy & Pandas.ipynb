{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca24b7b8-9386-4242-bb7a-73b26d66e89f",
   "metadata": {},
   "source": [
    "# Why We Need Data & Importance of Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07f29b-a808-494b-9d8c-f9dd5138e079",
   "metadata": {},
   "source": [
    "![Alt text](imgs/data_has_better_idea_slide_01.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9c25f9d-c3f3-4d30-b34d-2b1ef13c7d38",
   "metadata": {},
   "source": [
    "# The Most Popular Data Processing Tools Today in DS/ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d42602-4e32-42d0-80d8-5bafa7aa8f39",
   "metadata": {},
   "source": [
    "![Alt text](imgs/data_has_better_idea_slide_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d790538-09ae-4e33-bcaf-08c9097c1933",
   "metadata": {},
   "source": [
    "# Data Processing and Manipulation with NumPy, Pandas, Huggingface Datasets, and Working with APIs\n",
    "\n",
    "## Objectives\n",
    "- Understand the basics of NumPy and Pandas for data processing.\n",
    "- Learn how to use Huggingface Datasets for data manipulation.\n",
    "- Explore working with APIs for data acquisition.\n",
    "- Apply knowledge through hands-on examples and exercises.ng.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63951687-758d-41bf-8bcf-4d627bbdf876",
   "metadata": {},
   "source": [
    "<!-- ![Alt text](imgs/finallpandas_.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a89db0-85ac-46a7-a6e9-2a4c36c18251",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Data processing and manipulation are crucial skills in data science and machine learning. In this lecture, we will cover the main functionality and common use-cases of NumPy, Pandas, Huggingface Datasets, and working with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a61dd6-093b-4f73-8a75-a918aef74e08",
   "metadata": {},
   "source": [
    "# NumPy Basics\n",
    "NumPy (Numerical Python) is a library that provides support for arrays, matrices, and many mathematical functions. It is widely used in data processing, scientific computing, and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996bfada-540c-4140-9755-acd345de6f34",
   "metadata": {},
   "source": [
    "![Alt text](imgs/what-is-numpy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a766bd-9bea-40d5-ba16-18e1fdd77111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the numpy library (uncomment the line below if not already installed)\n",
    "# !pip install numpy\n",
    "\n",
    "# Importing NumPy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18edc33-776e-4f94-b650-10eba78f1ffb",
   "metadata": {},
   "source": [
    "### Creating Arrays\r\n",
    "We can create arrays using various functions like `np.array()`, `np.zeros()`, `np.ones()`, `np.arange()`, and `np.linspace()`.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a5d7db-09ed-40bc-affe-703fe4c670eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array from a list\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Array:\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5ff5f3-6279-4332-b03a-240f14ba3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zeros Array:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array of zeros\n",
    "zeros_arr = np.zeros((3, 3))\n",
    "print(\"Zeros Array:\\n\", zeros_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8e4251-dcf3-4cfb-8a8d-59dd92f5c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Array:\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array of ones\n",
    "ones_arr = np.ones((2, 4))\n",
    "print(\"Ones Array:\\n\", ones_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc90860-f36f-4fdc-ac4a-2405dcf1dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range Array: [0 2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array with a range of values\n",
    "range_arr = np.arange(0, 10, 2)\n",
    "print(\"Range Array:\", range_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7bd0ef-070f-470f-a982-4ebbe8212d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linspace Array: [0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "# Creating an array with linearly spaced values\n",
    "linspace_arr = np.linspace(0, 1, 5)\n",
    "print(\"Linspace Array:\", linspace_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b00503-66e7-412f-8362-fd875c95bd44",
   "metadata": {},
   "source": [
    "### Array Operations\r\n",
    "NumPy allows us to perform element-wise operations on arrays, such as addition, subtraction, multiplication, and division\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9546a3fb-505f-4576-8f1a-6ac2a2db7de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5]\n",
      "Array after multiplication by 2: [ 2  4  6  8 10]\n"
     ]
    }
   ],
   "source": [
    "# Element-wise operations\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = arr * 2\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Array after multiplication by 2:\", arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08000d23-03ec-4780-9328-fc7b0366d8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Arrays: [ 3  6  9 12 15]\n"
     ]
    }
   ],
   "source": [
    "# Adding two arrays\n",
    "arr3 = arr + arr2\n",
    "print(\"Sum of Arrays:\", arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429fcb16-249a-4752-93b2-d00c8a05fac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array after subtraction: [1 2 3 4 5]\n",
      "Array after division: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Other operations\n",
    "print(\"Array after subtraction:\", arr2 - arr)\n",
    "print(\"Array after division:\", arr2 / arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ad0bb-3f74-4d7e-b76d-5c7a7181c0fa",
   "metadata": {},
   "source": [
    "### Mathematical Functions\r\n",
    "NumPy provides many mathematical functions to perform operations like mean, standard deviation, sum, dot product, etc\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373afe6d-047d-4fd9-b936-3cc62e9077b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.0\n",
      "Standard Deviation: 1.4142135623730951\n",
      "Sum: 15\n",
      "Dot Product: 130\n"
     ]
    }
   ],
   "source": [
    "# Array for mathematical operations\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Mean\n",
    "print(\"Mean:\", np.mean(arr))\n",
    "\n",
    "# Standard Deviation\n",
    "print(\"Standard Deviation:\", np.std(arr))\n",
    "\n",
    "# Sum\n",
    "print(\"Sum:\", np.sum(arr))\n",
    "\n",
    "# Dot Product\n",
    "arr2 = np.array([6, 7, 8, 9, 10])\n",
    "print(\"Dot Product:\", np.dot(arr, arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d776b-ad1f-4884-ab06-8938c17ab798",
   "metadata": {},
   "source": [
    "### Broadcasting and Vectorization\n",
    "NumPy's broadcasting and vectorization features allow us to perform operations on arrays of different shapes and sizes efficiently.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee67046f-4c69-4a6d-8975-68f4304fdc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting Example: [11 22 33 44 55]\n",
      "Vectorized Sum: 15\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "broadcast_arr = arr + np.array([10, 20, 30, 40, 50])\n",
    "print(\"Broadcasting Example:\", broadcast_arr)\n",
    "\n",
    "# Vectorization\n",
    "vectorized_sum = np.sum(arr)\n",
    "print(\"Vectorized Sum:\", vectorized_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc9712-d640-4c4c-a2e4-cdfaaefe711f",
   "metadata": {},
   "source": [
    "### Summary\r\n",
    "In this notebook, we covered:\r\n",
    "- Creating arrays using different functions.\r\n",
    "- Performing basic array operations.\r\n",
    "- Indexing, slicing, and reshaping arrays.\r\n",
    "- Using mathematical functions.\r\n",
    "- Understanding broadcasting and vectorization.\r\n",
    "\r\n",
    "NumPy is a powerful library that forms the foundation for many data processing and scientific computing tasks. With these basics, you can start leveraging NumPy for your pojects.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5ce05-e281-48a7-9692-72fe0bbba7a2",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "## Introduction to Pandas\r\n",
    "Pandas is a library that provides data structures and data analysis tools for Python. It is widely used for data cleaning, preparation, and analysis.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae9bfd-929c-4113-b8ec-45d2a163c332",
   "metadata": {},
   "source": [
    "![Alt text](imgs/__.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "443ab731-2384-41d7-83ad-4f74ac821edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the pandas library (uncomment the line below if not already installed)\n",
    "# !pip install pandas\n",
    "\n",
    "# Importing Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45548197-8e2c-4614-9fd8-85672a53f659",
   "metadata": {},
   "source": [
    "### Creating DataFrames\r\n",
    "We can create DataFrames using various methods like `pd.DataFrame()`, `pd.read_csv()`, and `pd.read_excel()`\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e14fa54-0ec9-4ff9-9530-30e81dfd5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "       Name  Age\n",
      "0    Alice   25\n",
      "1      Bob   30\n",
      "2  Charlie   35\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame from a dictionary\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame:\\n\", df)\n",
    "\n",
    "# Creating a DataFrame from a CSV file\n",
    "# Uncomment the line below if you have a CSV file to read\n",
    "# df_csv = pd.read_csv('data.csv')\n",
    "# print(\"DataFrame from CSV:\\n\", df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914873f-559f-4f8d-9cde-f5dbb9fd220a",
   "metadata": {},
   "source": [
    "### Data Selection and Filtering\r\n",
    "We can select and filter data using methods like `.loc[]` and `.iloc[]`\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75beaac5-93d5-4c36-b0b5-34be48ae8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column\n",
    "print(\"Name Column:\\n\", df['Name'])\n",
    "\n",
    "# Selecting multiple columns\n",
    "print(\"\\nName and Age Columns:\\n\", df[['Name', 'Age']])\n",
    "\n",
    "# Filtering rows based on a condition\n",
    "filtered_df = df[df['Age'] > 30]\n",
    "print(\"\\nFiltered DataFrame (Age > 30):\\n\", filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ad791-a3f0-4870-94c9-f8d5047fbcb3",
   "metadata": {},
   "source": [
    "### Data Manipulation\r\n",
    "We can add or remove columns, handle missing values, and perform various other data manipulation tasks\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa0845f-2d67-4665-8edf-d445f485c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['City'] = ['New York', 'Los Angeles', 'Chicago']\n",
    "print(\"DataFrame with New Column:\\n\", df)\n",
    "\n",
    "# Removing a column\n",
    "df.drop('City', axis=1, inplace=True)\n",
    "print(\"\\nDataFrame after Removing Column:\\n\", df)\n",
    "\n",
    "# Handling missing values\n",
    "df_with_nan = df.copy()\n",
    "df_with_nan.loc[1, 'Age'] = None\n",
    "print(\"\\nDataFrame with Missing Value:\\n\", df_with_nan)\n",
    "\n",
    "# Filling missing values\n",
    "df_filled = df_with_nan.fillna(0)\n",
    "print(\"\\nDataFrame after Filling Missing Values:\\n\", df_filled)\n",
    "\n",
    "# Dropping rows with missing values\n",
    "df_dropped = df_with_nan.dropna()\n",
    "print(\"\\nDataFrame after Dropping Missing Values:\\n\", df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7555b15-c33c-417a-a339-f86000ab0426",
   "metadata": {},
   "source": [
    "### Grouping and Aggregation\r\n",
    "We can group data and perform aggregation operations using `.groupby()` and `.agg()`\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b8e43-956a-49d5-91fa-0dbb7d983acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data\n",
    "grouped_df = df.groupby('Age').count()\n",
    "print(\"Grouped DataFrame:\\n\", grouped_df)\n",
    "\n",
    "# Aggregation\n",
    "agg_df = df.groupby('Age').agg({'Name': 'count', 'Age': 'mean'})\n",
    "print(\"\\nAggregated DataFrame:\\n\", agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5a0db-0d39-4583-857f-169976d39e00",
   "metadata": {},
   "source": [
    "### Merging and Joining Data\r\n",
    "We can merge and join data using `pd.merge()` and `pd.concat()`\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a8e6b-9c2d-4a75-9cc7-005d2c4ece35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Age': [25, 30]})\n",
    "merged_df = pd.merge(df1, df2, on='ID')\n",
    "print(\"Merged DataFrame:\\n\", merged_df)\n",
    "\n",
    "# Concatenating DataFrames\n",
    "df3 = pd.DataFrame({'ID': [3], 'Name': ['Charlie'], 'Age': [35]})\n",
    "concat_df = pd.concat([merged_df, df3])\n",
    "print(\"\\nConcatenated DataFrame:\\n\", concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca77e69-6c44-4245-bfe2-6d3fe8a41b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2], 'Age': [25, 30]})\n",
    "merged_df = pd.merge(df1, df2, on='ID')\n",
    "print(\"Merged DataFrame:\\n\", merged_df)\n",
    "\n",
    "# Concatenating DataFrames\n",
    "df3 = pd.DataFrame({'ID': [3], 'Name': ['Charlie'], 'Age': [35]})\n",
    "concat_df = pd.concat([merged_df, df3])\n",
    "print(\"\\nConcatenated DataFrame:\\n\", concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e28f91-3f8d-4d72-b814-5e46106db93c",
   "metadata": {},
   "source": [
    "### Summary\r\n",
    "In this notebook, we covered:\r\n",
    "- Creating DataFrames using different methods.\r\n",
    "- Selecting and filtering data.\r\n",
    "- Performing data manipulation tasks.\r\n",
    "- Grouping and aggregating data.\r\n",
    "- Merging and joining DataFrames.\r\n",
    "\r\n",
    "Pandas is a versatile library that provides powerful data manipulation and analysis tools. With these basics, you can start leveraging Pandas for your data pojects.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2739620-8e7b-4523-9d26-61d7a3ed2a4a",
   "metadata": {},
   "source": [
    "# Huggingface Datasets Basics\r\n",
    "\r\n",
    "In this notebook, we will explore the basics of the Huggingface Datasets library, which provides a standardized interface for accessing and processing large datasets used in Natural Language Processing (NLP).\r\n",
    "\r\n",
    "## Introduction to Huggingface Datasets\r\n",
    "The Huggingface Datasets library is a powerful tool for loading, processing, and managing datasets, especially in the context of NLP. It provides a simple and efficient way to handle large-scale dataets.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe1111ca-2686-45a4-a034-03e5d0b707f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Installing the datasets library (uncomment the line below if not already installed)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# !pip install datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# Installing the datasets library (uncomment the line below if not already installed)\n",
    "# !pip install datasets\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71103b6-5940-4f42-aa67-19d2e529e408",
   "metadata": {},
   "source": [
    "## Loading Datasets\r\n",
    "We can load datasets using the `load_dataset` function. The library includes many pre-configured datasets\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24dc690c-92ec-435d-88eb-ecfab68f1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Dataset:\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Loading the IMDB dataset\n",
    "dataset = load_dataset('imdb')\n",
    "print(\"IMDB Dataset:\\n\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c3bb7e-bc9b-4caf-adc9-dd51c70dd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(type(dataset['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9e3cb-a64b-407d-82f9-8dc64982a193",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\r\n",
    "We can explore the dataset to understand its structure, including the features and examples\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba6b2f-b65c-4390-b47d-66066738581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the structure of the dataset\n",
    "print(\"Dataset Features:\\n\", dataset['train'].features)\n",
    "\n",
    "# Viewing an example from the training set\n",
    "print(\"\\nExample from the Training Set:\\n\", dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166df6b4-d838-4586-9508-eb297e2cca7b",
   "metadata": {},
   "source": [
    "## Splitting the Dataset\r\n",
    "Datasets can be split into training, validation, and test sets\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf46641-23b7-4c77-b624-db914d308507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test sets\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "print(\"Training Set Size:\", len(train_dataset))\n",
    "print(\"Test Set Size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7875-269e-42b2-98f4-485b25b89ad9",
   "metadata": {},
   "source": [
    "## Selecting and Filtering Data\r\n",
    "We can select specific subsets of the data or filter based on certain conditions\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1abd42-1483-41bb-bef4-8bbb7de8115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the first 5 examples from the training set\n",
    "subset = train_dataset.select([0, 1, 2, 3, 4])\n",
    "print(\"Subset of Training Set:\\n\", subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7839f-542a-4d0e-897f-8a3115b4ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(example: dict) -> dict:\n",
    "    return example['label'] == 1\n",
    "\n",
    "# Filtering examples with a specific condition\n",
    "filtered_dataset = train_dataset.filter(lambda x: filter_func(x))\n",
    "print(\"\\nFiltered Dataset (label == 1):\\n\", filtered_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c275699-0b5f-4466-8f05-87efa59e011b",
   "metadata": {},
   "source": [
    "## Applying Transformations\r\n",
    "We can apply transformations to the dataset, such as tokenization or data augmentation\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23800c78-f929-4244-9826-fe8a6f9d105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_words(example: dict) -> dict:\n",
    "    example['words'] = example['text'].split(' ')\n",
    "    return example\n",
    "\n",
    "# Apply the split_text_into function to the dataset\n",
    "processed_dataset = train_dataset.map(split_text_into_words)\n",
    "print(\"Tokenized Dataset Example:\\n\", processed_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd222f-6d5a-4ed3-9513-8a97271dbb4f",
   "metadata": {},
   "source": [
    "## Splitting the Dataset\r\n",
    "Datasets can be split into training, validation, and test sets\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d475c1b-d0c9-4d8b-ae04-976d9ec07670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test sets\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "print(\"Training Set Size:\", len(train_dataset))\n",
    "print(\"Test Set Size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73e180-0eb8-4922-a058-d2388c18ff7a",
   "metadata": {},
   "source": [
    "## Multiprocessing\r\n",
    "We can leverage multiprocessing to speed up data processing tasks\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194522ab-6df3-43ab-8487-3915fcb58f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiprocessing with map\n",
    "import multiprocessing\n",
    "\n",
    "# Number of processes\n",
    "num_proc = multiprocessing.cpu_count()\n",
    "print(f'{num_proc} processess could be run in that computer simoultaneously')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e576b-2435-4d77-ae54-b1e099a26b02",
   "metadata": {},
   "source": [
    "## Conver to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c484b-49b9-48af-a43f-36352a48d04b",
   "metadata": {},
   "source": [
    "Padnas DataFrame & Huggingface Dataset ყველაზე პოპულარული ბიბლიოთეკებია, ამიტომ მარტივად არის შესაძლებელი მონაცემების ერთი ფორმატიდან მეორეში გადატანა."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9d2562-19ea-4794-8c2c-cc2ea7c3fb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# ჩავტვირთოთ მონაცემები Dataset კლასში\n",
    "dataset = load_dataset('imdb', split='train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665cc806-e37c-42dd-8192-7ec5380f0103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Huggingface Dataset -> Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4757e8bc-1b8b-4cfa-8b10-e5b145c77ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas DataFrame -> Huggingface Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13291821-ce41-4391-8208-e5577370d3ef",
   "metadata": {},
   "source": [
    "## Summary\r\n",
    "In this notebook, we covered:\r\n",
    "- Loading datasets using Huggingface Datasets.\r\n",
    "- Shuffling the dataset.\r\n",
    "- Filtering data based on specific conditions.\r\n",
    "- Applying transformations using the `map` function.\r\n",
    "- Splitting the dataset into training and test sets.\r\n",
    "- Removing columns from the dataset.\r\n",
    "- Using multiprocessing to speed up data processing tasks.\r\n",
    "\r\n",
    "The Huggingface Datasets library provides a streamlined and efficient workflow for handling large-scale datasets. With these basics, you can start leveraging this powerful tool for your data processng needs.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fefa9c-ce07-4b25-adc3-8a62c7f09ec3",
   "metadata": {},
   "source": [
    "## Introduction to APIs\n",
    "APIs provide a way for different applications to communicate with each other. We will use the `requests` library to send HTTP requests to APIs and handle their responses.\n",
    "\n",
    "## Importing Libraries\n",
    "First, we need to import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "add4b5ec-179a-45fd-9910-7e70bdcdf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the requests library\n",
    "import requests\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f404601-4591-4a9a-a2f2-e0a9cd7db549",
   "metadata": {},
   "source": [
    "## Making a GET Request\r\n",
    "A GET request is used to retrieve data from a server\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be41a90e-8892-473e-8a6e-e0c50883ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response JSON:\n",
      "{'bpi': {'BTC': {'code': 'BTC',\n",
      "                 'description': 'Bitcoin',\n",
      "                 'rate': '1.0000',\n",
      "                 'rate_float': 1},\n",
      "         'USD': {'code': 'USD',\n",
      "                 'description': 'United States Dollar',\n",
      "                 'rate': '70,851.342',\n",
      "                 'rate_float': 70851.3421}},\n",
      " 'disclaimer': 'This data was produced from the CoinDesk Bitcoin Price Index '\n",
      "               '(USD). Non-USD currency data converted using hourly conversion '\n",
      "               'rate from openexchangerates.org',\n",
      " 'time': {'updated': 'Jun 5, 2024 19:28:27 UTC',\n",
      "          'updatedISO': '2024-06-05T19:28:27+00:00',\n",
      "          'updateduk': 'Jun 5, 2024 at 20:28 BST'}}\n"
     ]
    }
   ],
   "source": [
    "# Making a GET request to a sample API\n",
    "response = requests.get('https://api.coindesk.com/v1/bpi/currentprice/BTC.json')\n",
    "\n",
    "# Checking the status code of the response\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "# Parsing the JSON response\n",
    "data = response.json()\n",
    "print(\"Response JSON:\")\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0101e0-91d7-488d-bfca-bda1bec3edc6",
   "metadata": {},
   "source": [
    "## Making a POST Request\n",
    "A POST request is used to send data to a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c04d2168-22df-4059-9dc8-19c192d031f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key\": \"value\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"9\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.31.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-6660bc46-58ccee3d32f29e0a781487a3\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"134.19.243.33\", \n",
      "  \"url\": \"https://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    'key': 'value'\n",
    "}\n",
    "\n",
    "# The API endpoint to communicate with\n",
    "url_post = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "\n",
    "# A POST request to tthe API\n",
    "post_response = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
    "\n",
    "# Checking the status code of the response\n",
    "print(\"Status Code:\", post_response.status_code)\n",
    "\n",
    "print(post_response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
