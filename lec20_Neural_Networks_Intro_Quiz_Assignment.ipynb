{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cd5782",
   "metadata": {},
   "source": [
    "# Quiz: Introduction to Neural Networks (Analytical + Multiple Choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7575ffc",
   "metadata": {},
   "source": [
    "### Multiple Choice Questions\n",
    "\n",
    "1. What is the role of an activation function in a neural network?  \n",
    "a) To perform gradient descent  \n",
    "b) To make the network linear  \n",
    "c) To introduce non-linearity  \n",
    "d) To initialize weights\n",
    "\n",
    "2. Which of the following is **not** a common activation function?  \n",
    "a) ReLU  \n",
    "b) Sigmoid  \n",
    "c) Tanh  \n",
    "d) Logarithm\n",
    "\n",
    "3. Why do we need hidden layers in neural networks?  \n",
    "a) To make the model simpler  \n",
    "b) To help the model learn complex patterns  \n",
    "c) To reduce computation  \n",
    "d) To speed up inference\n",
    "\n",
    "4. What does a large number of parameters in a neural network increase the risk of?  \n",
    "a) Underfitting  \n",
    "b) Overfitting  \n",
    "c) Better generalization  \n",
    "d) Reduced accuracy\n",
    "\n",
    "5. Which optimizer updates parameters based on an exponentially weighted average of gradients?  \n",
    "a) SGD  \n",
    "b) Momentum  \n",
    "c) Adam  \n",
    "d) RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d565a2",
   "metadata": {},
   "source": [
    "### Analytical Questions\n",
    "\n",
    "1. You are building a neural network for a binary classification task. What are some factors youâ€™d consider when designing the number of layers and neurons?\n",
    "\n",
    "2. Explain how a neural network can approximate non-linear functions even though individual neurons are linear (without activation functions).\n",
    "\n",
    "3. How does adding more layers impact training time, memory usage, and risk of overfitting?\n",
    "\n",
    "4. If your network is not learning at all, what aspects would you check first and why?\n",
    "\n",
    "5. Describe in simple terms what happens during the forward pass and backward pass in training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b93135",
   "metadata": {},
   "source": [
    "# Assignment: Building and Interpreting a Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dd14b",
   "metadata": {},
   "source": [
    "### Task 1: Build a Neural Network from Scratch\n",
    "\n",
    "- Create a simple neural network with 1 hidden layer to solve XOR problem.\n",
    "- Use numpy only.\n",
    "- Use sigmoid activation.\n",
    "- Train it using manual forward and backward passes for 1000 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4216b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (starter)\n",
    "import numpy as np\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Initialize weights\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(2, 2)\n",
    "b1 = np.zeros((1, 2))\n",
    "W2 = np.random.randn(2, 1)\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Add forward + backward pass + training loop here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132a57b",
   "metadata": {},
   "source": [
    "### Task 2: Analyze a Trained Neural Network with Keras\n",
    "\n",
    "- Use Keras to build a model with 1 hidden layer for classifying points in 2D space.\n",
    "- Visualize decision boundary.\n",
    "- Experiment with different number of neurons and report what changes in the boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c55c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (starter)\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
