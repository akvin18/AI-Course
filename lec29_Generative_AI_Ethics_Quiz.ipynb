{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "cells": [{"id": "3fe9addb", "cell_type": "markdown", "source": "# Quiz: Generative AI Concepts and Ethical Considerations", "metadata": {}}, {"id": "61a34739", "cell_type": "markdown", "source": "### Multiple Choice Questions\n\n1. What is the main goal of Generative AI?  \na) Classifying images and text  \nb) Detecting fraud  \nc) Creating new content like text, images, or audio  \nd) Compressing large models\n\n2. Which of the following is a type of generative model?  \na) Convolutional Neural Network  \nb) GAN (Generative Adversarial Network)  \nc) Support Vector Machine  \nd) Random Forest\n\n3. What makes Variational Autoencoders (VAEs) different from standard autoencoders?  \na) They compress more  \nb) They use reinforcement learning  \nc) They introduce probabilistic sampling to generate new data  \nd) They only work on images\n\n4. What is a potential ethical issue with deepfake technology?  \na) Energy efficiency  \nb) Licensing models  \nc) Spreading misinformation  \nd) Feature extraction\n\n5. Which of the following helps reduce bias in generative AI models?  \na) More layers  \nb) Using pre-trained embeddings  \nc) Curated and representative training data  \nd) Data augmentation only\n\n6. What is a major challenge in evaluating generative models?  \na) Lack of training tools  \nb) Absence of structured data  \nc) Subjectivity and lack of ground truth  \nd) Too many labels\n\n7. Which model is commonly used for high-quality text generation?  \na) VAE  \nb) GAN  \nc) Transformer  \nd) Naive Bayes\n\n8. Which of these is a legal concern related to generative AI?  \na) Matrix multiplication  \nb) GPU temperature  \nc) Ownership of AI-generated content  \nd) Model training loss\n\n9. What kind of content can GANs generate?  \na) Only classification labels  \nb) Synthetic data like faces, scenes, and art  \nc) Time series  \nd) Rule-based predictions\n\n10. How can misuse of generative AI be mitigated?  \na) Removing model weights  \nb) Avoiding documentation  \nc) Implementing transparency, safety checks, and usage policies  \nd) Disabling fine-tuning\n", "metadata": {}}, {"id": "f7ca5d51", "cell_type": "markdown", "source": "### Analytical Questions\n\n1. Compare GANs and Diffusion Models in terms of training complexity and output quality.\n\n2. How can developers ensure consent and fairness in datasets used for training generative models?\n\n3. Describe a real-world risk of deploying an unmonitored generative model online.\n\n4. Why is transparency important in generative AI systems? How can it be implemented?\n\n5. In what ways can generative models perpetuate bias? Give an example.\n\n6. Suppose a company uses a generative model trained on copyrighted material. What legal and ethical questions arise?\n\n7. What steps could be taken to build ethical guardrails for generative image or video generation tools?\n\n8. Discuss the difficulty of evaluating the accuracy or utility of generated text. How is it different from classification tasks?\n\n9. How might generative AI be used both positively and negatively in the context of journalism?\n\n10. How should regulations evolve to account for generative AI models being open-sourced?\n", "metadata": {}}]}