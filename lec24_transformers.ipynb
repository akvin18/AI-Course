{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8cd527",
   "metadata": {},
   "source": [
    "# Sequence to Sequence ამოცანები"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb4b247b",
   "metadata": {},
   "source": [
    "Sequence to Sequence ამოცანა შეიძლება განვსაზღვროთ როგორც ფუნქცია f, რომელიც გარდაქმნის შემავალ მიმდევრობას X შესაბამის გამომავალ მიმდევრობაში Y :\n",
    "\n",
    "f: X → Y\n",
    "სადაც:\n",
    "- X = (x₁, x₂, ..., xₙ) არის შემავალი მიმდევრობა (Input Sequence)\n",
    "- Y = (y₁, y₂, ..., yₘ) არის გამომავალი მიმდევრობა (Output Sequence)\n",
    "\n",
    "ყურადღება მიაქციეთ, რომ n და m შეიძლება იყოს განსხვავებული სიგრძის, ანუ შემავალი და გამომავალი მიმდევრობების სიგრძეები შეიძლება არ იყოს ერთმანეთის ტოლი.\n",
    "\n",
    "seq-to-seq ამოცანები შეიძლება შეეხებოდეს, როგორც ტექსტის მიმდევრობებს, ასევე ნებისმიერ სხვა მოდალობას, როგორებიცაა აუდიო სიგნალები, ფოტო, ვიდეო და სხვა. ამ ტიპის ამოცანების მაგალითებია:\n",
    "\n",
    "- მანქანური თარგმანი:\n",
    "    - შემავალი მიმდევრობა: წინადადება ერთ ენაზე\n",
    "    - გამომავალი მიმდევრობა: იგივე წინადადება სხვა ენაზე\n",
    "    - მაგალითი: \"Hello, how are you?\" → \"გამარჯობა, როგორ ხარ?\"\n",
    "\n",
    "- ტექსტის შეჯამება:\n",
    "    - შემავალი მიმდევრობა: გრძელი ტექსტი ან დოკუმენტი\n",
    "    - გამომავალი მიმდევრობა: ტექსტის მოკლე შეჯამება\n",
    "    - მაგალითი: [გრძელი სტატია] → \"სტატია აღწერს კლიმატის ცვლილების გავლენას ოკეანეებზე\"\n",
    "\n",
    "- დიალოგის სისტემები:\n",
    "    - შემავალი მიმდევრობა: მომხმარებლის შეკითხვა ან მოთხოვნა\n",
    "    - გამომავალი მიმდევრობა: სისტემის პასუხი\n",
    "    - მაგალითი: \"რა არის დღეს ამინდის პროგნოზი?\" → \"დღეს მოსალოდნელია მზიანი ამინდი, მაქსიმალური ტემპერატურა 25°C\"\n",
    "\n",
    "- კოდის გენერაცია:\n",
    "    - შემავალი მიმდევრობა: პროგრამის აღწერა ბუნებრივ ენაზე\n",
    "    - გამომავალი: პროგრამული კოდი\n",
    "    - მაგალითი: \"შექმენი ფუნქცია, რომელიც დაითვლის ფიბონაჩის მიმდევრობას\" → [შესაბამისი Python კოდი]\n",
    "\n",
    "- ტექსტიდან მეტყველების სინთეზი:\n",
    "    - შემავალი მიმდევრობა: წერილობითი ტექსტი\n",
    "    - გამომავალი მიმდევრობა: ფონემების ან აუდიო სიგნალების მიმდევრობა\n",
    "    - მაგალითი: \"გამარჯობა\" → [სიტყვის შესაბამისი გახმოვანება]\n",
    "\n",
    "- ხმის ამოცნობა (ტრანსკრიფცია):\n",
    "    - შემავალი მიმდევრობა: აუდიო სიგნალების მიმდევრობა\n",
    "    - გამომავალი მიმდევრობა: ტრანსკრიპტი ტექსტის სახით\n",
    "    - მაგალითი: [აუდიო ფაილი] → \"გამარჯობა, როგორ ხარ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a33f24de735e6",
   "metadata": {},
   "source": [
    "<video src=\"https://lena-voita.github.io/resources/lectures/seq2seq/general/enc_dec_prob_idea.mp4\" controls autoplay loop style=\"display: block; margin: 0 auto\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed695105",
   "metadata": {},
   "source": [
    "ამგვარი ამოცანების გადაჭრისთვის Encoder-Decoder არქიტექტურა გამოიყენება:\n",
    "\n",
    "- Encoder - კითხულობს მთელს შემავალი მიმდევრობას X = (x₁, x₂, ..., xₙ) და ქმნის მის კარგ რეპრეზენტაციას;\n",
    "- Decoder - იყენებს Encoder-ის რეპრეზენტაციას სამიზნე მიმდევრობის დასაგენერირებლად.\n",
    "\n",
    "როგორც წესი, დეკოდირება ნაბიჯ-ნაბიჯ ხდება. მაგალითად, მანქანური თარგმნის შემთხვევაში, წინადადების თარგმანი სიტყვა-სიტყვა გენერირდება. Decoder თითოეული სიტყვის დაგენერირებამდე გვაძლევს სავარაუდო სიტყვების ალბათურ განაწილებას, საიდანაც შეგვიძლია ამოვირჩიოთ ყველაზე შესაფერისი კანდიდატი.\n",
    "\n",
    "ეს პროცესი შეიძლება აღვწეროთ შემდეგნაირად:\n",
    "\n",
    "1. Encoder ამუშავებს შემავალ მიმდევრობას _X_ და ქმნის კონტექსტუალურ რეპრეზენტაციას _C_.\n",
    "1. Decoder იწყებს გამომავალი მიმდევრობის _Y_ გენერირებას, იყენებს რა _C_-ს და უკვე დაგენერირებულ სიმბოლოებს.\n",
    "1. თითოეული ნაბიჯისთვის _t_, Decoder აგენერირებს ალბათურ განაწილებას _P(yₜ|y₁, ..., yₜ₋₁, C)_ მომდევნო სიმბოლოსთვის.\n",
    "1. ამ განაწილებიდან ირჩევა ყველაზე სავარაუდო სიტყვა (ტოკენი).\n",
    "1. პროცესი გრძელდება, სანამ არ დაგენერირდება სპეციალური დასრულების სიმბოლო ან არ მიიღწევა წინასწარ განსაზღვრული მაქსიმალური სიგრძე."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539b353",
   "metadata": {},
   "source": [
    "# Transformer: Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e361ca",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/model-min.png\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d06c8",
   "metadata": {},
   "source": [
    "2017 წელს Google-ის მკვლევარებმა თავიანთ ნაშრომში (Attention is All You Need) გამოაქვეყნეს Transformer არქიტექტურა. როგორც სახელიდან ჩანს ამ არქიტექტურის ფუნდამენტს წარმოადგენს Attention მექანიზმი, რომელიც 2014 წლიდან გამოიყენებოდა seq-to-seq ამოცანების გადაჭრაში. მთავარი უპირატესობები, რაც ამ არქიტექტურამ წინამორბედებთან შედარებით აჩვენა:\n",
    "- შეუძლია შემავალი მიმდევრობის პარალელური დამუშავება GPU-ს გამოყენებით, მაშინ როცა რეკურენტული ნეირონული ქსელები (RNN) შემავალ ინფორმაციას სიტყვა-სიტყვა ამუშავებენ;\n",
    "- შეუძლია გაცილებით გრძელ ტექსტებთან მუშაობა ხარისხის დაკარგვის გარეშე;\n",
    "- პარალელურობის გამო მარტივად შეიძლება ამ არქიტექტურის მასშტაბირება;\n",
    "- გაცილების ჩქარი ტრეინინგი;\n",
    "- მნიშვნელოვნად გაუმჯობესებული შედეგები ენის მოდელირების, თარგმნის, კითხვებზე პასუხის გაცემის და სხვა NLP ამოცანებში."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36740cae",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/rnn_vs_transformer_river-min.png\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c7e6f",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fafbd97e",
   "metadata": {},
   "source": [
    "<img src=\"./images/Encoder.png\" width=200 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b8b3e",
   "metadata": {},
   "source": [
    "მთავარი დიაგრამის მარცხენა ნაწილი - Encoder ამუშავებს შემომავალ მიმდევრობას, შედგება N ცალი მიმდევრობით გადაბმული Encoder ბლოკისაგან (ნაცრისფერი ნაწილი), რომელთაგან თითოეული:\n",
    "\n",
    "1. Self-Attention მექანიზმით:\n",
    "    - თითოეული ტოკენის რეპრეზენტაცია \"ყურადღებას\" აქცევს სხვა ტოკენებს.\n",
    "    - ეს საშუალებას აძლევს მოდელს, გაითვალისწინოს კონტექსტი მთელი მიმდევრობიდან.\n",
    "\n",
    "1. Feed-Forward ქსელით:\n",
    "    - ანახლებს/გარდაქმნის კონკრეტული ტოკენის რეპრეზენტაციას.\n",
    "    - ზრდის მოდელის უნარს, დაამუშაოს რთული პატერნები."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c5c86",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1cf901c",
   "metadata": {},
   "source": [
    "<img src=\"./images/Decoder.png\" width=200 style=\"display: block; margin: 0 auto\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "მთავარი დიაგრამის მარჯვენა ნაწილი - Decoder იღებს Encoder-ის საბოლოო layer-ის რეპრეზენტაციებს და აგენერირებს სამიზნე მიმდევრობას. ისიც, Encoder-ის მსგავსად, შედგება N ცალი მიმდევრობით გადაბმული Decoder ბლოკისაგან (ნაცრისფერი ნაწილი), რომელთაგან თითოეული:\n",
    "\n",
    "1. Masked Self-Attention მექანიზმით:\n",
    "    - ამუშავებს უკვე დაგენერირებულ ტოკენებს და \"ყურადღებას\" აქცევს მათ.\n",
    "\n",
    "1. Encoder-Decoder Attention მექანიზმით:\n",
    "    - აკავშირებს Decoder-ის მიმდინარე მდგომარეობას Encoder-ით მიღებულ ტოკენის რეპრეზენტაციებთან.\n",
    "    - საშუალებას აძლევს Decoder-ს, ფოკუსირდეს შემავალი მიმდევრობის რელევანტურ ნაწილებზე.\n",
    "\n",
    "1. Feed-Forward ქსელით:\n",
    "    - ანახლებს/გარდაქმნის თითოეული ტოკენის რეპრეზენტაციას.\n",
    "    - ზრდის მოდელის უნარს, დაამუშაოს რთული პატერნები."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4727c4",
   "metadata": {},
   "source": [
    "### ტექსტის გენერაცია"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b465a1",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/transformer_original.gif\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a23489",
   "metadata": {},
   "source": [
    "ამ ანიმაციაზე ნაჩვენებია ენკოდირებისა და დეკოდირების დროს რეპრეზენტაციების მიმოცვლა.\n",
    "\n",
    "Encoding:\n",
    "1. ენკოდირება იწყება სიტყვების \"I\" \"arrived\" \"at\" \"the\" საწყისი ემბედინგებით (ცარიელი შავი რგოლები);\n",
    "1. self-attention-ით ხდება ამ ტოკენების რეპრეზენტაციების \"გამდიდრება\" (ერთმანეთზე ყურადღების მიქცევა);\n",
    "1. რგოლის შევსება/გაფერადება ნიშნავს feed-forward layer-ის გავლას;\n",
    "1. self-attention და feed-forward მეორდება 3-ჯერ (ამ ანიმაციაში N=3);\n",
    "\n",
    "Decoding:\n",
    "1. ენკოდირებისგან განსხვავებით დეკოდირება არა პარალელურად, არამედ სიტყვა-სიტყვა მიმდინარეობს;\n",
    "1. აქაც ვიწყებთ საწყისი ემბედინგებით (ცარიელი შავი რგოლები);\n",
    "1. self-attention-ით უკვე დაგენერირებულ ტოკენებს ექცევა ყურადღება;\n",
    "1. cross-attention-ით ყურადღება ექცევა encoder-დან წამოსულ ტოკენებს;\n",
    "1. რგოლის შევსება/გაფერადება ნიშნავს feed-forward layer-ის გავლას;\n",
    "1. self-attention, cross-attention და feed-forward მეორდება 3-ჯერ (ამ ანიმაციაშიც N=3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b83ff1",
   "metadata": {},
   "source": [
    "როგორც ხედავთ, Encoder-ისა და Decoder-ის არქიტექტურა თითქმის იდენტურია, განსხვავება მხოლოდ Decoder-ის cross-attention-ია, როდესაც იგი ყურადღებას აქცევს Encoder-ის მიერ შექმნილ შემავალი მიმდევრობის რეპრეზენტაციებს."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158536f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
